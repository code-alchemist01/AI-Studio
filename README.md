# ğŸ¨ KapsamlÄ± AI Studio

Bu proje, en son AI modellerini kullanarak metin ve gÃ¶rsellerden video, 3D model ve geliÅŸmiÅŸ gÃ¶rseller oluÅŸturabilen kapsamlÄ± bir yapay zeka uygulamasÄ±dÄ±r.

## ğŸš€ Ã–zellikler

### ğŸ“ Metin â†’ GÃ¶rsel
- **Model**: FLUX.1-dev (black-forest-labs/FLUX.1-dev)
- **Ã–zellik**: Metinden yÃ¼ksek kaliteli gÃ¶rseller oluÅŸturma
- **Ã‡Ã¶zÃ¼nÃ¼rlÃ¼k**: 1024x1024'e kadar

### ğŸ–¼ï¸ GÃ¶rsel â†’ GeliÅŸmiÅŸ GÃ¶rsel
- **Model**: Stable Diffusion XL Refiner (stabilityai/stable-diffusion-xl-refiner-1.0)
- **Ã–zellik**: Mevcut gÃ¶rselleri geliÅŸtirme ve iyileÅŸtirme
- **Format**: PNG, JPG, JPEG destekli

### ğŸ“ Metin â†’ Video
- **Model**: LTX-Video (Lightricks/LTX-Video)
- **Ã–zellik**: Metinden gerÃ§ek zamanlÄ± video oluÅŸturma
- **Ã‡Ã¶zÃ¼nÃ¼rlÃ¼k**: 1216Ã—704, 30 FPS

### ğŸ–¼ï¸ GÃ¶rsel â†’ Video
- **Model**: Stable Video Diffusion (stabilityai/stable-video-diffusion-img2vid-xt)
- **Ã–zellik**: Statik gÃ¶rsellerden video oluÅŸturma
- **Ã‡Ã¶zÃ¼nÃ¼rlÃ¼k**: 576x1024, 25 frame

### ğŸ–¼ï¸ GÃ¶rsel â†’ 3D Model
- **Model**: Hunyuan3D-2 (tencent/Hunyuan3D-2)
- **Ã–zellik**: GÃ¶rsellerden yÃ¼ksek Ã§Ã¶zÃ¼nÃ¼rlÃ¼klÃ¼ 3D model oluÅŸturma
- **Format**: GLB, OBJ Ã§Ä±ktÄ± formatlarÄ±

### ğŸ“ Metin â†’ 3D Model
- **Model**: Stable Zero123 (stabilityai/stable-zero123)
- **Ã–zellik**: Metinden 3D model oluÅŸturma
- **Teknik**: Score Distillation Sampling (SDS)

## ğŸ› ï¸ Kurulum

### Gereksinimler
- Python 3.8+
- CUDA destekli GPU (Ã¶nerilen)
- 16GB+ RAM
- 50GB+ disk alanÄ±

### 1. Repository'yi klonlayÄ±n
```bash
git clone <repository-url>
cd Multilangual
```

### 2. Sanal ortam oluÅŸturun
```bash
python -m venv venv
venv\Scripts\activate  # Windows
# source venv/bin/activate  # Linux/Mac
```

### 3. BaÄŸÄ±mlÄ±lÄ±klarÄ± yÃ¼kleyin
```bash
pip install -r requirements.txt
```

### 4. HuggingFace Token'Ä±nÄ± ayarlayÄ±n

#### YÃ¶ntem 1: Environment Variable
```bash
set HUGGINGFACE_TOKEN=YOUR_ACCES_TOKEN
```

#### YÃ¶ntem 2: .env dosyasÄ± (zaten yapÄ±landÄ±rÄ±lmÄ±ÅŸ)
`.env` dosyasÄ±nda token zaten ayarlanmÄ±ÅŸ durumda.

#### YÃ¶ntem 3: Streamlit Secrets (zaten yapÄ±landÄ±rÄ±lmÄ±ÅŸ)
`.streamlit/secrets.toml` dosyasÄ±nda token zaten ayarlanmÄ±ÅŸ durumda.

## ğŸš€ KullanÄ±m

### UygulamayÄ± baÅŸlatÄ±n
```bash
streamlit run main.py
```

Uygulama varsayÄ±lan olarak `http://localhost:8501` adresinde Ã§alÄ±ÅŸacaktÄ±r.

### Web ArayÃ¼zÃ¼
1. TarayÄ±cÄ±nÄ±zda `http://localhost:8501` adresine gidin
2. Sol menÃ¼den kullanmak istediÄŸiniz AI aracÄ±nÄ± seÃ§in
3. Gerekli parametreleri girin
4. "OluÅŸtur" butonuna tÄ±klayÄ±n
5. SonuÃ§larÄ± gÃ¶rÃ¼ntÃ¼leyin ve indirin

## ğŸ“ Proje YapÄ±sÄ±

```
Multilangual/
â”œâ”€â”€ main.py                 # Ana Streamlit uygulamasÄ±
â”œâ”€â”€ requirements.txt        # Python baÄŸÄ±mlÄ±lÄ±klarÄ±
â”œâ”€â”€ .env                   # Environment variables
â”œâ”€â”€ README.md              # Bu dosya
â”œâ”€â”€ .streamlit/
â”‚   â”œâ”€â”€ config.toml        # Streamlit konfigÃ¼rasyonu
â”‚   â””â”€â”€ secrets.toml       # Streamlit secrets
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ text2image.py      # FLUX.1-dev model handler
â”‚   â”œâ”€â”€ image2image.py     # SDXL Refiner model handler
â”‚   â”œâ”€â”€ text2video.py      # LTX-Video model handler
â”‚   â”œâ”€â”€ image2video.py     # Stable Video Diffusion handler
â”‚   â”œâ”€â”€ image23d.py        # Hunyuan3D-2 model handler
â”‚   â””â”€â”€ text23d.py         # Stable Zero123 model handler
â””â”€â”€ utils/
    â”œâ”€â”€ __init__.py
    â””â”€â”€ helpers.py         # YardÄ±mcÄ± fonksiyonlar
```

## âš™ï¸ KonfigÃ¼rasyon

### GPU AyarlarÄ±
EÄŸer birden fazla GPU'nuz varsa, kullanÄ±lacak GPU'yu belirtebilirsiniz:
```bash
set CUDA_VISIBLE_DEVICES=0
```

### Model Cache
Modeller varsayÄ±lan olarak `./models_cache` dizininde saklanÄ±r. Bu dizini deÄŸiÅŸtirmek iÃ§in:
```bash
set HF_HOME=C:\path\to\your\cache
set TRANSFORMERS_CACHE=C:\path\to\your\cache
```

### Streamlit AyarlarÄ±
Port ve adres ayarlarÄ± `.streamlit/config.toml` dosyasÄ±nda yapÄ±landÄ±rÄ±labilir.

## ğŸ”§ Sorun Giderme

### CUDA Bellek HatasÄ±
EÄŸer GPU bellek hatasÄ± alÄ±yorsanÄ±z:
1. Daha kÃ¼Ã§Ã¼k batch size kullanÄ±n
2. Model CPU offloading'i etkinleÅŸtirin (zaten aktif)
3. Daha dÃ¼ÅŸÃ¼k Ã§Ã¶zÃ¼nÃ¼rlÃ¼k kullanÄ±n

### Model YÃ¼kleme HatasÄ±
1. Ä°nternet baÄŸlantÄ±nÄ±zÄ± kontrol edin
2. HuggingFace token'Ä±nÄ±n doÄŸru olduÄŸundan emin olun
3. Disk alanÄ±nÄ±zÄ±n yeterli olduÄŸundan emin olun

### YavaÅŸ Performans
1. GPU kullandÄ±ÄŸÄ±nÄ±zdan emin olun
2. CUDA sÃ¼rÃ¼mÃ¼nÃ¼zÃ¼ kontrol edin
3. Daha az inference step kullanÄ±n

## ğŸ“Š Sistem Gereksinimleri

### Minimum
- CPU: Intel i5 / AMD Ryzen 5
- RAM: 16GB
- GPU: GTX 1060 6GB / RTX 2060
- Disk: 50GB boÅŸ alan

### Ã–nerilen
- CPU: Intel i7 / AMD Ryzen 7
- RAM: 32GB+
- GPU: RTX 3080 / RTX 4070+
- Disk: 100GB+ SSD

## ğŸ¤ KatkÄ±da Bulunma

1. Fork edin
2. Feature branch oluÅŸturun (`git checkout -b feature/amazing-feature`)
3. Commit edin (`git commit -m 'Add amazing feature'`)
4. Push edin (`git push origin feature/amazing-feature`)
5. Pull Request oluÅŸturun

## ğŸ“„ Lisans

Bu proje MIT lisansÄ± altÄ±nda lisanslanmÄ±ÅŸtÄ±r. Detaylar iÃ§in `LICENSE` dosyasÄ±na bakÄ±n.

## ğŸ™ TeÅŸekkÃ¼rler

- [Black Forest Labs](https://huggingface.co/black-forest-labs) - FLUX.1-dev
- [Stability AI](https://huggingface.co/stabilityai) - SDXL Refiner, Stable Video Diffusion, Stable Zero123
- [Lightricks](https://huggingface.co/Lightricks) - LTX-Video
- [Tencent](https://huggingface.co/tencent) - Hunyuan3D-2
- [Streamlit](https://streamlit.io/) - Web framework
- [HuggingFace](https://huggingface.co/) - Model hosting ve diffusers library

## ğŸ“ Ä°letiÅŸim

SorularÄ±nÄ±z iÃ§in issue aÃ§abilir veya pull request gÃ¶nderebilirsiniz.

---

**Not**: Bu uygulama eÄŸitim ve araÅŸtÄ±rma amaÃ§lÄ±dÄ±r. Ticari kullanÄ±m iÃ§in model lisanslarÄ±nÄ± kontrol edin.